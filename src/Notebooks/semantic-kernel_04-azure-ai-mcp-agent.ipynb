{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92a4c472",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d9c0f3",
   "metadata": {},
   "source": [
    "# Connecting to a Remote MCP Server with Semantic Kernel\n",
    "\n",
    "This notebook demonstrates how to connect to a remote MCP Server using **Semantic Kernel's** `MCPSsePlugin`. The **Model Context Protocol (MCP)** enables scalable and modular tool integration across distributed systems. \n",
    "\n",
    "<br/>\n",
    "\n",
    "> **Why Use Model Context Protocol (MCP)?**\n",
    ">\n",
    ">MCP allows agents to discover, invoke, and manage tools dynamically across remote servers.  \n",
    ">It promotes modularity, scalability, and separation of concerns, making it easier to maintain and extend AI systems as they grow in complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6c3f6ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel import Kernel\n",
    "from user_plugins import WeatherPlugin, DataCenterPlugin\n",
    "from semantic_kernel.agents import ChatCompletionAgent\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "from dotenv import load_dotenv\n",
    "from os import environ\n",
    "import asyncio\n",
    "\n",
    "from semantic_kernel.connectors.mcp import MCPSsePlugin\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "kernel = Kernel()\n",
    "\n",
    "kernel.add_service(AzureChatCompletion(\n",
    "    service_id=\"chat\",\n",
    "    deployment_name=environ[\"AZURE_OPENAI_MODEL\"],\n",
    "    endpoint=environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    api_key=environ[\"AZURE_OPENAI_API_KEY\"] ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feaf10c3",
   "metadata": {},
   "source": [
    "## Connecting to a remote MCP server via sse\n",
    "\n",
    "- Server-Sent Events (SSE) is a mechanism for establishing a continuous, one-way data stream from the server to a client, such as a web application. This allows the server to push updates or messages to the client without the client needing to constantly poll for new information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d34908b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's 60°F and foggy in San Francisco today.\n"
     ]
    }
   ],
   "source": [
    "async with MCPSsePlugin(\n",
    "    name=\"weather\",\n",
    "    url=f\"{environ[\"MCP_SERVER_URL\"]}/weather/sse\",\n",
    ") as weather_plugin:\n",
    "\n",
    "    agent = ChatCompletionAgent(\n",
    "        kernel=kernel, \n",
    "        name=\"WeatherAgent\", \n",
    "        plugins=[weather_plugin, ]\n",
    "    )\n",
    "    response = await agent.get_response(messages=\"What's the weather like in sf today?\")\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ef9900d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "\n",
      "What data centers are in 'critical'?\n",
      "The following data centers are currently in a \"critical\" alarm status:\n",
      "\n",
      "1. **DC-NYC1**\n",
      "   - **Zone:** B2, C3\n",
      "   - Conditions include high temperatures, elevated power usage, and varying backup statuses.\n",
      "\n",
      "2. **DC-CHI2**\n",
      "   - **Zone:** A1, B2, C3\n",
      "   - Issues related to temperature spikes and cooling systems.\n",
      "\n",
      "3. **DC-OMA1**\n",
      "   - **Zone:** A1, B2, C3\n",
      "   - Observations include cooling load impacts and power consumption abnormalities.\n",
      "  \n",
      "Specific details (e.g., timestamp, power draw, temperature, etc.) are available for each data center. Let me know if you need more granular insights into any particular case.\n",
      "\n",
      "------------------------------------------------\n",
      "\n",
      "------------------------------------------------\n",
      "\n",
      "Describe the resource intensity of data center facility infrastructure\n",
      "Data center facility infrastructure resource intensity is primarily defined using two metrics: **Power Usage Effectiveness (PUE)** and **Water Usage Effectiveness (WUE)**.\n",
      "\n",
      "### Definitions:\n",
      "1. **Power Usage Effectiveness (PUE)**:\n",
      "   - PUE is the ratio of the total electricity demand of the data center to the electricity demand of the IT equipment. \n",
      "   - Mathematically: \\( \\text{PUE} = \\frac{\\text{Total Electricity Demand}}{\\text{IT Equipment Demand}} \\)\n",
      "   - It measures how efficiently the infrastructure uses power relative to computing resources. A lower PUE indicates higher efficiency.\n",
      "\n",
      "2. **Water Usage Effectiveness (WUE)**:\n",
      "   - WUE evaluates the total water consumption of a data center divided by the electricity demand of IT equipment.\n",
      "   - WUE is expressed in liters per kWh and primarily stems from cooling processes and electricity generation.\n",
      "\n",
      "### Influencing Factors:\n",
      "- **Cooling Systems**: Cooling infrastructure plays a dominant role in resource consumption. Types of cooling systems and their operational settings significantly affect both PUE and WUE.\n",
      "- **Operational Practices**: Energy and water usage vary with different operational setups and maintenance practices.\n",
      "- **Climatic Conditions**: Data centers in different regions are subjected to climatic variability, influencing the efficiency of cooling systems.\n",
      "\n",
      "### Measurement Approach:\n",
      "- Advanced thermodynamics-based models simulate PUE and WUE metrics, incorporating parameters such as cooling system types and regional climatic conditions.\n",
      "- Simulations are paired with assumptions on the geographic distribution of data centers and the corresponding cooling systems.\n",
      "\n",
      "### Key Resource Impacts:\n",
      "1. **Energy**: In 2023, data centers consumed approximately 176 TWh in the U.S., highlighting their significant power demand.\n",
      "2. **Water**:\n",
      "   - Indirect water footprint reaches nearly 800 billion liters annually, primarily tied to electricity generation.\n",
      "   - On-site cooling water usage also contributes substantially.\n",
      "3. **GHG Emissions**:\n",
      "   - Total emissions from energy consumption are equivalent to 61 billion kilograms of CO₂ annually (0.34 kg/kWh on average).\n",
      "\n",
      "Addressing resource intensity requires better metrics for benchmarking efficiency, alongside collaborations to optimize cooling and electricity use while reducing environmental impacts. Efforts such as novel energy performance repositories and improved transparency in resource reporting are strategies for minimizing resource impacts.\n",
      "\n",
      "------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from contextlib import AsyncExitStack\n",
    "\n",
    "plugin_names = [\"weather\", \"search\", \"energy\"]\n",
    "\n",
    "messages = [\n",
    "    \"What data centers are in 'critical'?\",\n",
    "    \"Describe the resource intensity of data center facility infrastructure\"\n",
    "]\n",
    "\n",
    "\n",
    "async with AsyncExitStack() as stack:\n",
    "    plugins = []\n",
    "    for plugin_name in plugin_names:\n",
    "        plugin = await stack.enter_async_context(\n",
    "            MCPSsePlugin(\n",
    "                name=plugin_name,\n",
    "                url=f\"{environ['MCP_SERVER_URL']}/{plugin_name}/sse\"\n",
    "            )\n",
    "        )\n",
    "        plugins.append(plugin)\n",
    "\n",
    "    agent = ChatCompletionAgent(\n",
    "        kernel=kernel,\n",
    "        name=\"MultiPluginAgent\",\n",
    "        plugins=plugins\n",
    "    )\n",
    "\n",
    "\n",
    "    for msg in messages:\n",
    "        print(\"------------------------------------------------\\n\")\n",
    "        print(msg)\n",
    "        response = await agent.get_response(messages=msg)\n",
    "        print(response)\n",
    "        print(\"\\n------------------------------------------------\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
