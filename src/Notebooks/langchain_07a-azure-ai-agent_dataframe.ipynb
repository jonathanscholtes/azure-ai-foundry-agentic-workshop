{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f08b39e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082d338d",
   "metadata": {},
   "source": [
    "# Subgraph for Querying Structured Data\n",
    "\n",
    "This notebook demonstrates how to use a **subgraph** to write and execute queries against a structured data source.\n",
    "\n",
    "- Use a Parquet file stored in an **Azure Storage Account** as the structured dataset.\n",
    "- Generate Python code dynamically to filter a **pandas DataFrame** based on user queries.\n",
    "- Show how agents can reason over structured data sources to extract precise, relevant information.\n",
    "- Demonstrates how to use a custom subgraph builder (`langchain_07b_dataframe_subgraph_builder.py`) to easily construct child agents.\n",
    "\n",
    "This approach highlights how agents can interact with tabular data in real-time through code generation and execution.\n",
    "\n",
    "ðŸ”— [Subgraphs in LangGraph](https://langchain-ai.github.io/langgraph/concepts/low_level/#subgraphs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b53467d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from os import environ\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from typing_extensions import TypedDict,Literal\n",
    "from langgraph.types import Command\n",
    "from langgraph.graph import MessagesState, StateGraph, START, END\n",
    "from IPython.display import Image, display\n",
    "from  user_tools import get_weather_tool\n",
    "from user_functions import vector_search,get_datafame_from_storage\n",
    "from utils import pretty_print_messages\n",
    "from langchain_core.messages import HumanMessage,SystemMessage\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "load_dotenv(override=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665b3129",
   "metadata": {},
   "source": [
    "## Subgraph: Interfece with Data Center Data (Azure Storage Dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80958f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_07b_dataframe_subgraph_builder import DataFrameQuerySubgraphBuilder\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    temperature=0,\n",
    "    azure_deployment=environ[\"AZURE_OPENAI_MODEL\"],\n",
    "    api_version=environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    ")\n",
    "\n",
    "df = get_datafame_from_storage('data/usage.parquet')\n",
    "\n",
    "builder = DataFrameQuerySubgraphBuilder(llm, df)\n",
    "subgraph_datacenter = builder.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdb9324",
   "metadata": {},
   "source": [
    "# Build Parent Graph to leverage Data Center Graph when needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c46103a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "members = [\"weather\" , \"datacenter\"]\n",
    "\n",
    "options = members + [\"FINISH\"]\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are a supervisor tasked with managing a conversation between the\"\n",
    "    f\" following workers: {members}. Given the following user request,\"\n",
    "    \" respond with the worker to act next. Each worker will perform a\"\n",
    "    \" task and respond with their results and status. When finished,\"\n",
    "    \" respond with FINISH.\")\n",
    "\n",
    "class Router(TypedDict):\n",
    "    \"\"\"Worker to route to next. If no workers needed, route to FINISH.\"\"\"\n",
    "\n",
    "    next: Literal[*options]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efbeb016",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = create_react_agent(llm, tools=[get_weather_tool])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e46f16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weather(state: MessagesState) -> Command[Literal[\"supervisor\"]]:\n",
    "    \n",
    "    result = llm_with_tools.invoke(state)\n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"weather\")\n",
    "            ]\n",
    "        },\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "\n",
    "def supervisor(state: MessagesState) -> Command[Literal[*members, \"__end__\"]]:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "    ] + state[\"messages\"]\n",
    "    response = llm.with_structured_output(Router).invoke(messages)\n",
    "    goto = response[\"next\"]\n",
    "    if goto == \"FINISH\":\n",
    "        goto = END\n",
    "\n",
    "    return Command(goto=goto, update={\"next\": goto})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e79400e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"weather\", weather)\n",
    "builder.add_node(\"datacenter\", subgraph_datacenter)\n",
    "builder.add_node(\"supervisor\", supervisor)\n",
    "\n",
    "builder.set_entry_point(\"supervisor\")\n",
    "\n",
    "graph = builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce6d2dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update from node supervisor:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Update from node datacenter:\n",
      "\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Return Average Data Center Temperatures?\n",
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "You are a Python data assistant.\n",
      "\n",
      "DataFrame schema:\n",
      "timestamp: datetime64[ns]\n",
      "data_center_id: object\n",
      "zone: object\n",
      "power_draw_kw: float64\n",
      "it_load_kw: float64\n",
      "cooling_load_kw: float64\n",
      "pue: float64\n",
      "temperature_c: float64\n",
      "humidity_percent: float64\n",
      "ups_load_percent: float64\n",
      "battery_backup_status: object\n",
      "grid_energy_source: object\n",
      "co2_emissions_kg: float64\n",
      "alarm_status: object\n",
      "operator_notes: object\n",
      "\n",
      "Sample rows:\n",
      "|    | timestamp                  | data_center_id   | zone   |   power_draw_kw |   it_load_kw |   cooling_load_kw |   pue |   temperature_c |   humidity_percent |   ups_load_percent | battery_backup_status   | grid_energy_source   |   co2_emissions_kg | alarm_status   | operator_notes          |\n",
      "|---:|:---------------------------|:-----------------|:-------|----------------:|-------------:|------------------:|------:|----------------:|-------------------:|-------------------:|:------------------------|:---------------------|-------------------:|:---------------|:------------------------|\n",
      "|  0 | 2025-04-14 15:15:13.724337 | DC-CHI2          | C3     |          170.78 |        91.85 |             70    |  1.86 |           22.49 |               49.4 |               63.9 | offline                 | grid                 |             118.07 | normal         | Rebooted cooling system |\n",
      "|  1 | 2025-04-14 15:00:13.724337 | DC-NYC1          | B2     |          190.82 |       148.05 |             35.62 |  1.29 |           29.66 |               55.6 |               78.7 | charging                | solar                |             108.75 | critical       |                         |\n",
      "|  2 | 2025-04-14 14:45:13.724337 | DC-NYC1          | B2     |          111.11 |        75.98 |             26.06 |  1.46 |           23.13 |               37.2 |               60.9 | discharging             | diesel               |              58.88 | warning        | Checked UPS levels      |\n",
      "\n",
      "Given the user request, return Python code that operates on `panda df` and answers the question.Your code **must** assign the final result to a variable named `result`.\n",
      "Only return codeâ€”no explanation or commentary.Do **not** include triple backticks (` ``` `)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: generate_query\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "# Calculate the average temperature for each data center\n",
      "result = df.groupby('data_center_id')['temperature_c'].mean()\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: run_query\n",
      "\n",
      "| data_center_id   |   temperature_c |\n",
      "|:-----------------|----------------:|\n",
      "| DC-CHI2          |         24.1167 |\n",
      "| DC-NYC1          |         25.2838 |\n",
      "| DC-OMA1          |         24.8296 |\n",
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "You are a helpful assistant that answers the user's question given the returned data\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: explain_result\n",
      "\n",
      "The average temperatures for the data centers are as follows:\n",
      "\n",
      "- **DC-CHI2**: 24.12Â°C\n",
      "- **DC-NYC1**: 25.28Â°C\n",
      "- **DC-OMA1**: 24.83Â°C\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": \"Return Average Data Center Temperatures?\"}]}):\n",
    "   pretty_print_messages(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ea5d801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update from node supervisor:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Update from node datacenter:\n",
      "\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "how many data centers are there?\n",
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "You are a Python data assistant.\n",
      "\n",
      "DataFrame schema:\n",
      "timestamp: datetime64[ns]\n",
      "data_center_id: object\n",
      "zone: object\n",
      "power_draw_kw: float64\n",
      "it_load_kw: float64\n",
      "cooling_load_kw: float64\n",
      "pue: float64\n",
      "temperature_c: float64\n",
      "humidity_percent: float64\n",
      "ups_load_percent: float64\n",
      "battery_backup_status: object\n",
      "grid_energy_source: object\n",
      "co2_emissions_kg: float64\n",
      "alarm_status: object\n",
      "operator_notes: object\n",
      "\n",
      "Sample rows:\n",
      "|    | timestamp                  | data_center_id   | zone   |   power_draw_kw |   it_load_kw |   cooling_load_kw |   pue |   temperature_c |   humidity_percent |   ups_load_percent | battery_backup_status   | grid_energy_source   |   co2_emissions_kg | alarm_status   | operator_notes          |\n",
      "|---:|:---------------------------|:-----------------|:-------|----------------:|-------------:|------------------:|------:|----------------:|-------------------:|-------------------:|:------------------------|:---------------------|-------------------:|:---------------|:------------------------|\n",
      "|  0 | 2025-04-14 15:15:13.724337 | DC-CHI2          | C3     |          170.78 |        91.85 |             70    |  1.86 |           22.49 |               49.4 |               63.9 | offline                 | grid                 |             118.07 | normal         | Rebooted cooling system |\n",
      "|  1 | 2025-04-14 15:00:13.724337 | DC-NYC1          | B2     |          190.82 |       148.05 |             35.62 |  1.29 |           29.66 |               55.6 |               78.7 | charging                | solar                |             108.75 | critical       |                         |\n",
      "|  2 | 2025-04-14 14:45:13.724337 | DC-NYC1          | B2     |          111.11 |        75.98 |             26.06 |  1.46 |           23.13 |               37.2 |               60.9 | discharging             | diesel               |              58.88 | warning        | Checked UPS levels      |\n",
      "\n",
      "Given the user request, return Python code that operates on `panda df` and answers the question.Your code **must** assign the final result to a variable named `result`.\n",
      "Only return codeâ€”no explanation or commentary.Do **not** include triple backticks (` ``` `)\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: generate_query\n",
      "\n",
      "result = df['data_center_id'].nunique()\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: run_query\n",
      "\n",
      "3\n",
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "You are a helpful assistant that answers the user's question given the returned data\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: explain_result\n",
      "\n",
      "There are 3 unique data centers in the dataset.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": \"how many data centers are there?\"}]}):\n",
    "   pretty_print_messages(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e89ed35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update from node supervisor:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Update from node weather:\n",
      "\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: weather\n",
      "\n",
      "The weather in San Francisco is currently 60Â°F and foggy.\n",
      "\n",
      "\n",
      "Update from node supervisor:\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]}):\n",
    "   pretty_print_messages(step)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
