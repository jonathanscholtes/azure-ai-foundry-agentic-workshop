{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62f54770",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\joscholt\\Documents\\GitHub\\Azure-AI-Foundry-Agentic-Workshop\\.venv\\Lib\\site-packages\\~ydantic_core'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "! pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7498db30",
   "metadata": {},
   "source": [
    "# Querying Structured Data with the Semantic Kernel Process Framework\n",
    "\n",
    "This notebook demonstrates how to use the **Semantic Kernel Process Framework** to orchestrate AI-driven workflows. It shows how an agent can dynamically generate and execute Python code to query structured data‚Äîspecifically, a Parquet file stored in an Azure Storage Account‚Äîby filtering a pandas DataFrame to answer user queries.\n",
    "\n",
    "## Process Framework\n",
    "\n",
    "The **Process Framework** streamlines the automation of complex workflows using an event-driven model. Each step executes user-defined Kernel Functions, allowing flexible and modular workflow design.\n",
    "\n",
    "üîó [Learn more about the Process Framework](https://learn.microsoft.com/en-us/semantic-kernel/frameworks/process/process-framework)\n",
    "\n",
    "> ‚ö†Ô∏è The Process Framework package is currently experimental and may change before reaching preview or GA.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "87b4320e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import asyncio\n",
    "from typing import ClassVar\n",
    "\n",
    "from pydantic import BaseModel, Field, ConfigDict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Optional, Any\n",
    "\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.chat_completion_client_base import ChatCompletionClientBase\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "from semantic_kernel.contents import ChatHistory\n",
    "from semantic_kernel.functions import kernel_function\n",
    "from semantic_kernel.processes import ProcessBuilder\n",
    "from semantic_kernel.processes.kernel_process import KernelProcessStep, KernelProcessStepContext, KernelProcessStepState,KernelProcessEvent\n",
    "from semantic_kernel.processes.local_runtime.local_kernel_process import start\n",
    "\n",
    "\n",
    "from user_functions import get_datafame_from_storage\n",
    "from dotenv import load_dotenv\n",
    "from os import environ\n",
    "\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddccd2a",
   "metadata": {},
   "source": [
    "### Configure the kernel with an AI Service and connection details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "0fa3bbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kernel = Kernel()\n",
    "kernel.add_service(AzureChatCompletion(\n",
    "    service_id=\"chat\",\n",
    "    deployment_name=environ[\"AZURE_OPENAI_MODEL\"],\n",
    "    endpoint=environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    api_key=environ[\"AZURE_OPENAI_API_KEY\"] ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2511010c",
   "metadata": {},
   "source": [
    "### Define the process steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "b1813cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the state model\n",
    "class DataFrameProcessState(BaseModel):\n",
    "    chat_history: ChatHistory | None = None\n",
    "\n",
    "\n",
    "\n",
    "# Step 1: Generate Query Step\n",
    "class GenerateQueryStep(KernelProcessStep[DataFrameProcessState]):\n",
    "    state: DataFrameProcessState = Field(default_factory=DataFrameProcessState)\n",
    "\n",
    "\n",
    "    @kernel_function\n",
    "    async def generate_query(self, context: KernelProcessStepContext, data:dict):\n",
    "        df=data['df']\n",
    "        user_input = data['input']\n",
    "        \n",
    "        print(f\"{GenerateQueryStep.__name__}\\n\\t Generating Query for {user_input}\")\n",
    "\n",
    "        \n",
    "        if self.state.chat_history is None:\n",
    "            self.state.chat_history = ChatHistory()\n",
    "\n",
    "       \n",
    "        if df is None:\n",
    "            raise ValueError(\"DataFrame is not set in state.\")\n",
    "\n",
    "        schema = \"\\n\".join(f\"{col}: {dtype}\" for col, dtype in df.dtypes.items())\n",
    "        sample = df.head(3).to_markdown()\n",
    "\n",
    "        self.state.chat_history.add_user_message(user_input)\n",
    "\n",
    "        prompt = (\n",
    "            f\"You are a Python data assistant.\\n\\n\"\n",
    "            f\"DataFrame schema:\\n{schema}\\n\\nSample rows:\\n{sample}\\n\\n\"\n",
    "            \"Given the user request, return Python code that operates on `panda df` and assigns result to `result`.\"\n",
    "            \"Only return code. No explanation.\"\n",
    "            \"Do **not** include triple backticks (` ``` `)\"\n",
    "        )\n",
    "\n",
    "\n",
    "        self.state.chat_history.add_user_message(user_input)\n",
    "        self.state.chat_history.add_user_message(prompt)\n",
    "\n",
    "        chat_service, settings = kernel.select_ai_service(type=ChatCompletionClientBase)\n",
    "        response = await chat_service.get_chat_message_content(chat_history=self.state.chat_history, settings=settings)\n",
    "\n",
    "    \n",
    "        await context.emit_event(process_event=\"generated_query\", data={'df':df,'code':str(response), 'input':user_input})\n",
    "\n",
    "\n",
    "# Step 2: Run Query Step\n",
    "class RunQueryStep(KernelProcessStep[DataFrameProcessState]):\n",
    "    state: DataFrameProcessState = Field(default_factory=DataFrameProcessState)\n",
    "\n",
    "    @kernel_function\n",
    "    async def run_query(self, context: KernelProcessStepContext,data:dict):\n",
    "        df=data['df']\n",
    "        code = data['code']\n",
    "        user_input=data['input']\n",
    "\n",
    "        print(f\"{RunQueryStep.__name__}\\n\\t Running Code {code}\")\n",
    "\n",
    "        try:\n",
    "            local_env = {\"df\": df, \"pd\": pd, \"np\": np}\n",
    "            # Execute the generated code\n",
    "            exec(code, local_env)\n",
    "            response = local_env.get(\"result\")\n",
    "        except Exception as e:\n",
    "            response = f\"Execution error: {e}\"\n",
    "\n",
    "        # Emit event for next step\n",
    "        await context.emit_event(process_event=\"query_ran\",data={'df':df,'results':str(response),'input':user_input})\n",
    "\n",
    "\n",
    "# Step 3: Explain Result Step\n",
    "class ExplainResultStep(KernelProcessStep[DataFrameProcessState]):\n",
    "    state: DataFrameProcessState = Field(default_factory=DataFrameProcessState)\n",
    "\n",
    "    @kernel_function\n",
    "    async def explain_result(self, context: KernelProcessStepContext, data:dict):\n",
    "        \n",
    "        query_result=data['results']\n",
    "        user_input = data['input']\n",
    "        \n",
    "        print(f\"{ExplainResultStep.__name__}\\n\\t Explain Results {query_result}\")\n",
    "\n",
    "        if self.state.chat_history is None:\n",
    "            self.state.chat_history = ChatHistory()\n",
    "\n",
    "        self.state.chat_history.add_user_message(user_input)\n",
    "\n",
    "        explanation_prompt = f\"You are a helpful assistant that answers the user's question given the returned data\\n\\n{query_result}\"\n",
    "\n",
    "        self.state.chat_history.add_user_message(explanation_prompt)\n",
    "\n",
    "        # Get the explanation from the chat service\n",
    "        chat_service, settings = kernel.select_ai_service(type=ChatCompletionClientBase)\n",
    "        response = await chat_service.get_chat_message_content(chat_history=self.state.chat_history, settings=settings)\n",
    "\n",
    "        print(response)\n",
    "\n",
    "        # Emit event to indicate process completion\n",
    "        await context.emit_event(\"__end__\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077b958e",
   "metadata": {},
   "source": [
    "### Define the process flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "c6829242",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the process builder\n",
    "process_builder = ProcessBuilder(name=\"DataFrameQuery\")\n",
    "\n",
    "# Add the steps to the process\n",
    "query_step = process_builder.add_step(GenerateQueryStep)\n",
    "run_step = process_builder.add_step(RunQueryStep)\n",
    "explain_step = process_builder.add_step(ExplainResultStep)\n",
    "\n",
    "# Orchestrate the events between the steps\n",
    "process_builder.on_input_event(\"Start\").send_event_to(target=query_step)\n",
    "\n",
    "query_step.on_event(\"generated_query\").send_event_to(target=run_step, function_name=\"run_query\")\n",
    "\n",
    "run_step.on_event(\"query_ran\").send_event_to(target=explain_step, function_name=\"explain_result\")\n",
    "\n",
    "\n",
    "# Build the process\n",
    "kernel_process = process_builder.build()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1217f35e",
   "metadata": {},
   "source": [
    "### Load Data From Azure Storage Account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "d297de36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_datafame_from_storage('data/usage.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "f52ab50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenerateQueryStep\n",
      "\t Generating Query for Return Average Data Center Temperatures?\n",
      "RunQueryStep\n",
      "\t Running Code result = df['temperature_c'].mean()\n",
      "ExplainResultStep\n",
      "\t Explain Results 24.6198\n",
      "The average data center temperature returned is **24.62¬∞C**.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "user_input = \"Return Average Data Center Temperatures?\"\n",
    "\n",
    "\n",
    "# Starting the kernel process with the initial state\n",
    "async with await start(\n",
    "    process=kernel_process,\n",
    "    kernel=kernel,\n",
    "    initial_event=KernelProcessEvent(id=\"Start\", data={'df':df,'input':user_input}),\n",
    ") as process_context:\n",
    "    _ = await process_context.get_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "956240b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenerateQueryStep\n",
      "\t Generating Query for Return Average Data Center Temperatures?\n",
      "RunQueryStep\n",
      "\t Running Code result = df.groupby('data_center_id')['temperature_c'].mean()\n",
      "ExplainResultStep\n",
      "\t Explain Results data_center_id\n",
      "DC-CHI2    24.116739\n",
      "DC-NYC1    25.283846\n",
      "DC-OMA1    24.829643\n",
      "Name: temperature_c, dtype: float64\n",
      "To calculate the average temperature of the data centers, we can take the mean of the temperatures provided:\n",
      "\n",
      "Temperatures:  \n",
      "DC-CHI2: 24.116739¬∞C  \n",
      "DC-NYC1: 25.283846¬∞C  \n",
      "DC-OMA1: 24.829643¬∞C  \n",
      "\n",
      "**Average Temperature:**\n",
      "\n",
      "\\[\n",
      "\\text{Average} = \\frac{24.116739 + 25.283846 + 24.829643}{3} = 24.743409 \\, \\text{¬∞C}\n",
      "\\]\n",
      "\n",
      "The average temperature of the data centers is **24.74¬∞C**.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "user_input = \"Return Average Data Center Temperatures?\"\n",
    "\n",
    "\n",
    "# Starting the kernel process with the initial state\n",
    "async with await start(\n",
    "    process=kernel_process,\n",
    "    kernel=kernel,\n",
    "    initial_event=KernelProcessEvent(id=\"Start\", data={'df':df,'input':user_input}),\n",
    ") as process_context:\n",
    "    _ = await process_context.get_state()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
