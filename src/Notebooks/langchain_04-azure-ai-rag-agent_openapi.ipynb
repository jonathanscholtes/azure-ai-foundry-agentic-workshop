{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f08b39e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b53467d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from os import environ\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from typing_extensions import TypedDict,Literal\n",
    "from langgraph.types import Command\n",
    "from langgraph.graph import MessagesState, StateGraph, START, END\n",
    "from IPython.display import Image, display\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from  user_tools import get_weather_tool\n",
    "from user_functions import vector_search  \n",
    "from utils import pretty_print_messages\n",
    "from langchain_core.messages import HumanMessage,SystemMessage\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_community.agent_toolkits.openapi.toolkit import OpenAPIToolkit\n",
    "from langchain_community.agent_toolkits.openapi.planner import create_openapi_agent\n",
    "from langchain_community.utilities.requests import RequestsWrapper\n",
    "from langchain_community.tools.json.tool import JsonSpec\n",
    "from langchain_community.tools.openapi.utils.openapi_utils import OpenAPISpec\n",
    "from langchain_community.agent_toolkits.openapi.spec import reduce_openapi_spec\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "\n",
    "\n",
    "members = [\"document_search\", \"weather\", \"datacenter_energy_usage\"]\n",
    "\n",
    "options = members + [\"FINISH\"]\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are a supervisor tasked with managing a conversation between the\"\n",
    "    f\" following workers: {members}. Given the following user request,\"\n",
    "    \" respond with the worker to act next. Each worker will perform a\"\n",
    "    \" task and respond with their results and status. When finished,\"\n",
    "    \" respond with FINISH.n\\nNote: The 'datacenter_energy_usage' worker handles queries related to data center tabular quries on energy, power, or consumption topics.\"\n",
    ")\n",
    "\n",
    "class Router(TypedDict):\n",
    "    \"\"\"Worker to route to next. If no workers needed, route to FINISH.\"\"\"\n",
    "\n",
    "    next: Literal[*options]\n",
    "\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "        temperature=0,\n",
    "        azure_deployment=environ[\"AZURE_OPENAI_MODEL\"],\n",
    "        api_version=environ[\"AZURE_OPENAI_API_VERSION\"]\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f01d7f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_url = environ['OPENAPI_URL']\n",
    "response = requests.get(spec_url)\n",
    "response.raise_for_status()\n",
    "\n",
    "json_spec = reduce_openapi_spec(response.json())\n",
    "\n",
    "requests_wrapper = RequestsWrapper(headers={\"Authorization\": f\"Bearer {environ['AZURE_OPENAI_API_KEY']}\"})\n",
    "\n",
    "openapi_agent = create_openapi_agent(\n",
    "    json_spec,\n",
    "    requests_wrapper,\n",
    "    llm,\n",
    "    allow_dangerous_requests=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efbeb016",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = create_react_agent(llm, tools=[get_weather_tool])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e46f16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def document_search(state: MessagesState) -> Command[Literal[\"supervisor\"]]:\n",
    "    messages = state[\"messages\"]\n",
    "    last_user_message = next((msg for msg in reversed(messages)), None)\n",
    "    if not last_user_message:\n",
    "        return Command(goto=\"supervisor\")\n",
    "\n",
    "    query = last_user_message.content\n",
    "    context = vector_search(query)  \n",
    "\n",
    "    \n",
    "    messages.append(\n",
    "    SystemMessage(\n",
    "        content=(\n",
    "            f\"You are a helpful assistant. Use only the information in the context below to answer the user's question. \"\n",
    "            f\"If the context does not contain the answer, respond with \\\"I don't know.\\\"\\n\\nContext:\\n{context}\"\n",
    "        )\n",
    "    )\n",
    "    )\n",
    "\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=response.content, name=\"document_search\")\n",
    "            ]\n",
    "        },\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "\n",
    "\n",
    "def weather(state: MessagesState) -> Command[Literal[\"supervisor\"]]:\n",
    "    result = llm_with_tools.invoke(state)\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"weather\")\n",
    "            ]\n",
    "        },\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "\n",
    "\n",
    "def datacenter_energy_usage(state: MessagesState) -> Command[Literal[\"supervisor\"]]:\n",
    "    user_message = next(\n",
    "        (msg.content for msg in reversed(state[\"messages\"]) if isinstance(msg, HumanMessage)),\n",
    "        None\n",
    "    )\n",
    "\n",
    "    if not user_message:\n",
    "        raise ValueError(\"No user message found in state.\")\n",
    "\n",
    "    result = openapi_agent.invoke({\"input\": user_message})\n",
    "    final_output = result.get(\"output\", result)  \n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=final_output, name=\"datacenter_energy_usage\")\n",
    "            ]\n",
    "        },\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "\n",
    "\n",
    "def supervisor(state: MessagesState) -> Command[Literal[*members, \"__end__\"]]:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "    ] + state[\"messages\"]\n",
    "    response = llm.with_structured_output(Router).invoke(messages)\n",
    "    goto = response[\"next\"]\n",
    "    if goto == \"FINISH\":\n",
    "        goto = END\n",
    "\n",
    "    return Command(goto=goto, update={\"next\": goto})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e79400e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"document_search\", document_search)\n",
    "builder.add_node(\"weather\", weather)\n",
    "builder.add_node(\"datacenter_energy_usage\", datacenter_energy_usage)\n",
    "builder.add_node(\"supervisor\", supervisor)\n",
    "\n",
    "builder.set_entry_point(\"supervisor\")\n",
    "\n",
    "graph = builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0204c509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Unable to display the graph visualization. This won't affect the rest of the notebook.\n",
      "Reason: Failed to reach https://mermaid.ink/ API while trying to render your graph after 1 retries. To resolve this issue:\n",
      "1. Check your internet connection and try again\n",
      "2. Try with higher retry settings: `draw_mermaid_png(..., max_retries=5, retry_delay=2.0)`\n",
      "3. Use the Pyppeteer rendering method which will render your graph locally in a browser: `draw_mermaid_png(..., draw_method=MermaidDrawMethod.PYPPETEER)`\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(\"⚠️ Unable to display the graph visualization. This won't affect the rest of the notebook.\")\n",
    "    print(f\"Reason: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce6d2dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update from node supervisor:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: api_planner  \n",
      "Action Input: I need to find the right API calls to retrieve information about data centers with a 'critical' status.  \u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m1. Use the `GET /usage/energy-usage` endpoint with the query parameter `alarm_status=critical` to retrieve energy usage data for data centers with a 'critical' status. \n",
      "\n",
      "Step-by-step plan:\n",
      "1. Call `GET /usage/energy-usage` with the filter `alarm_status=critical` to retrieve information about data centers with a 'critical' alarm status.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI am ready to execute the API call to retrieve information about data centers with a 'critical' alarm status.  \n",
      "Action: api_controller  \n",
      "Action Input: Call `GET /usage/energy-usage` with the filter `alarm_status=critical`.  \u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to retrieve energy usage data for data centers where the `alarm_status` is `critical`. This requires calling the `GET /usage/energy-usage` endpoint with the appropriate filter.\n",
      "\n",
      "Action: Use the `requests_get` tool to call the API with the `alarm_status=critical` filter.\n",
      "Action Input: \n",
      "```json\n",
      "{\n",
      "  \"url\": \"https://api-foundry-lab-ex7ziqmhsxf8.azurewebsites.net/usage/energy-usage\",\n",
      "  \"params\": {\"alarm_status\": \"critical\"},\n",
      "  \"output_instructions\": \"Extract the ids and names of data centers with critical alarm status.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: Use the `requests_get` tool to call the API with the `alarm_status=critical` filter. is not a valid tool, try one of [requests_get, requests_post].\n",
      "Thought:\u001b[32;1m\u001b[1;3mIt seems I made an error in formatting the action input. I will retry using the correct tool and input format.\n",
      "\n",
      "Action: Use the `requests_get` tool to call the API with the `alarm_status=critical` filter.\n",
      "Action Input:\n",
      "```json\n",
      "{\n",
      "  \"url\": \"https://api-foundry-lab-ex7ziqmhsxf8.azurewebsites.net/usage/energy-usage\",\n",
      "  \"params\": {\"alarm_status\": \"critical\"},\n",
      "  \"output_instructions\": \"Extract the ids and names of data centers with critical alarm status.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: Use the `requests_get` tool to call the API with the `alarm_status=critical` filter. is not a valid tool, try one of [requests_get, requests_post].\n",
      "Thought:\u001b[32;1m\u001b[1;3mIt seems there is a persistent issue with executing the `requests_get` tool. I will carefully recheck the input format and retry the API call.\n",
      "\n",
      "Action: Retry using the `requests_get` tool to call the API with the `alarm_status=critical` filter.\n",
      "Action Input:\n",
      "```json\n",
      "{\n",
      "  \"url\": \"https://api-foundry-lab-ex7ziqmhsxf8.azurewebsites.net/usage/energy-usage\",\n",
      "  \"params\": {\"alarm_status\": \"critical\"},\n",
      "  \"output_instructions\": \"Extract the ids and names of data centers with critical alarm status.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: Retry using the `requests_get` tool to call the API with the `alarm_status=critical` filter. is not a valid tool, try one of [requests_get, requests_post].\n",
      "Thought:\u001b[32;1m\u001b[1;3mIt seems there is a misunderstanding or persistent issue with the tool execution. The tool name `requests_get` is correct, and the input format appears valid. However, the repeated error suggests there might be a problem with the environment or tool configuration. I cannot proceed further without resolving this issue.\n",
      "\n",
      "Final Answer: I encountered a persistent issue with executing the `requests_get` tool despite using the correct input format. The tool execution is not functioning as expected, and I cannot retrieve the data. Please verify the tool configuration or provide additional guidance to resolve this issue.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3mI encountered a persistent issue with executing the `requests_get` tool despite using the correct input format. The tool execution is not functioning as expected, and I cannot retrieve the data. Please verify the tool configuration or provide additional guidance to resolve this issue.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mIt seems there is an issue with executing the API call. I will need to troubleshoot or clarify the problem further. Let me attempt the action again to ensure the input format is correct, or I may need to escalate the issue.\n",
      "\n",
      "Action: api_controller  \n",
      "Action Input: Call `GET /usage/energy-usage` with the filter `alarm_status=critical`.  \u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to retrieve energy usage data for data centers with the filter `alarm_status=critical`. This will help me identify data centers with critical alarm statuses.\n",
      "\n",
      "Action: requests_get\n",
      "Action Input: {\"url\": \"https://api-foundry-lab-ex7ziqmhsxf8.azurewebsites.net/usage/energy-usage\", \"params\": {\"alarm_status\": \"critical\"}, \"output_instructions\": \"Extract the ids and names of data centers with critical alarm statuses.\"}\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"data_center_ids\": [\"DC-NYC1\", \"DC-CHI2\", \"DC-OMA1\"]\n",
      "}\n",
      "```\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe response only provided the `data_center_ids` without additional details like names or other information. However, the task is complete as I successfully retrieved the IDs of data centers with critical alarm statuses.\n",
      "\n",
      "Final Answer: The data centers with critical alarm statuses are:\n",
      "- ID: DC-NYC1\n",
      "- ID: DC-CHI2\n",
      "- ID: DC-OMA1\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3mThe data centers with critical alarm statuses are:\n",
      "- ID: DC-NYC1\n",
      "- ID: DC-CHI2\n",
      "- ID: DC-OMA1\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have successfully retrieved the information about data centers with a 'critical' alarm status.  \n",
      "Final Answer: The data centers with critical alarm statuses are:\n",
      "- ID: DC-NYC1\n",
      "- ID: DC-CHI2\n",
      "- ID: DC-OMA1\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Update from node datacenter_energy_usage:\n",
      "\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: datacenter_energy_usage\n",
      "\n",
      "The data centers with critical alarm statuses are:\n",
      "- ID: DC-NYC1\n",
      "- ID: DC-CHI2\n",
      "- ID: DC-OMA1\n",
      "\n",
      "\n",
      "Update from node supervisor:\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": \"What data centers are in 'critical'?\"}]}):\n",
    "   pretty_print_messages(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6fa4e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update from node supervisor:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Update from node document_search:\n",
      "\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: document_search\n",
      "\n",
      "The data center space types considered in the study are:\n",
      "\n",
      "1. **Telco Edge**: Small closets/rooms to micro data centers and network infrastructure deployed by communications companies as points of presence throughout their network.\n",
      "\n",
      "2. **Commercial Edge**: Network closets, server rooms, and micro-data centers supporting digital infrastructure and software delivery services for commercial and industrial edge locations.\n",
      "\n",
      "3. **Small and Medium Businesses (SMB)**: Data center deployments within internal facilities of small and medium businesses.\n",
      "\n",
      "4. **Enterprise Branch**: Remote and branch office (ROBO) deployments for large enterprises in their own internal facilities, such as network closets and server rooms.\n",
      "\n",
      "5. **Internal**: Data centers operated internally by enterprises for their own use.\n",
      "\n",
      "6. **Communications Service Providers (Comms SPs)**: Data centers run by telecommunications or cable companies to support internal services for enabling communication technology services.\n",
      "\n",
      "7. **Colocation – Small/Medium Scale**: Data centers built by local colocation companies providing retail leasing at smaller scales.\n",
      "\n",
      "8. **Colocation – Large Scale**: Data centers built by major colocation companies offering wholesale and retail colocation leasing, typically deploying large and mega data centers.\n",
      "\n",
      "9. **Hyperscale**: Data centers built by companies deploying internet services and platforms at massive scales. \n",
      "\n",
      "These space types vary in size, operational characteristics, and cooling systems.\n",
      "\n",
      "\n",
      "Update from node supervisor:\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": \"What are the Data Center Space Types?\"}]}):\n",
    "   pretty_print_messages(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e89ed35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update from node supervisor:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Update from node weather:\n",
      "\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: weather\n",
      "\n",
      "The weather in San Francisco is currently 60°F and foggy.\n",
      "\n",
      "\n",
      "Update from node supervisor:\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]}):\n",
    "   pretty_print_messages(step)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
