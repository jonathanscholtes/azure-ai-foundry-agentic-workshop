{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f08b39e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6307604d",
   "metadata": {},
   "source": [
    "# Multi-Agent Orchestration with Subgraphs\n",
    "\n",
    "This notebook showcases a multi-agent pattern using **subgraphs** to encapsulate agent workflows into independent, reusable components.\n",
    "\n",
    "- Build modular agent workflows that can be composed and orchestrated across complex systems.\n",
    "- Enable better maintainability and scalability by separating concerns into distinct subgraphs.\n",
    "- Demonstrates how to use a custom subgraph builder (`langchain_06b_subgraph_builder.py`) to easily construct child agents.\n",
    "\n",
    "Subgraphs make it easier to manage, reuse, and evolve your agent architectures over time.\n",
    "\n",
    "üîó [Subgraphs in LangGraph](https://langchain-ai.github.io/langgraph/concepts/low_level/#subgraphs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b53467d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from os import environ\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from typing_extensions import TypedDict,Literal\n",
    "from langgraph.types import Command\n",
    "from langgraph.graph import MessagesState, StateGraph, START, END\n",
    "from IPython.display import Image, display\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from  user_tools import get_weather_tool\n",
    "from user_functions import vector_search  \n",
    "from utils import pretty_print_messages\n",
    "from langchain_core.messages import HumanMessage,SystemMessage\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "load_dotenv(override=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b37c703",
   "metadata": {},
   "source": [
    "## Subgraph: Interfece with Data Center Data (RAG and Endpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b5ec2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_06b_subgraph_builder import SubgraphBuilder\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    temperature=0,\n",
    "    azure_deployment=environ[\"AZURE_OPENAI_MODEL\"],\n",
    "    api_version=environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    ")\n",
    "\n",
    "builder = SubgraphBuilder(llm)\n",
    "subgraph_datacenter = builder.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b5a2e2",
   "metadata": {},
   "source": [
    "# Build Parent Graph to leverage Data Center Graph when needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9d1d77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "members = [\"weather\" , \"datacenter\"]\n",
    "\n",
    "options = members + [\"FINISH\"]\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are a supervisor tasked with managing a conversation between the\"\n",
    "    f\" following workers: {members}. Given the following user request,\"\n",
    "    \" respond with the worker to act next. Each worker will perform a\"\n",
    "    \" task and respond with their results and status. When finished,\"\n",
    "    \" respond with FINISH.\")\n",
    "\n",
    "class Router(TypedDict):\n",
    "    \"\"\"Worker to route to next. If no workers needed, route to FINISH.\"\"\"\n",
    "\n",
    "    next: Literal[*options]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efbeb016",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm_with_tools = create_react_agent(llm, tools=[get_weather_tool])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e46f16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def weather(state: MessagesState) -> Command[Literal[\"supervisor\"]]:\n",
    "    \n",
    "    result = llm_with_tools.invoke(state)\n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"weather\")\n",
    "            ]\n",
    "        },\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "\n",
    "def supervisor(state: MessagesState) -> Command[Literal[*members, \"__end__\"]]:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "    ] + state[\"messages\"]\n",
    "    response = llm.with_structured_output(Router).invoke(messages)\n",
    "    goto = response[\"next\"]\n",
    "    if goto == \"FINISH\":\n",
    "        goto = END\n",
    "\n",
    "    return Command(goto=goto, update={\"next\": goto})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e79400e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"weather\", weather)\n",
    "builder.add_node(\"datacenter\", subgraph_datacenter)\n",
    "builder.add_node(\"supervisor\", supervisor)\n",
    "\n",
    "builder.set_entry_point(\"supervisor\")\n",
    "\n",
    "graph = builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce6d2dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update from node supervisor:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: api_planner  \n",
      "Action Input: I need to find the right API calls to retrieve information about data centers with a 'critical' status.  \u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m1. Use the `GET /usage/energy-usage` endpoint with a query parameter `alarm_status=critical` to retrieve energy usage data for data centers with a 'critical' status. \n",
      "\n",
      "Plan:  \n",
      "1. GET /usage/energy-usage with the query parameter `alarm_status=critical` to filter and retrieve information about data centers with a 'critical' status.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThought: I have the plan to retrieve information about data centers with a 'critical' status. I should now execute the plan using the API controller.  \n",
      "Action: api_controller  \n",
      "Action Input: GET /usage/energy-usage with the query parameter `alarm_status=critical`  \u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to retrieve energy usage data for data centers where the `alarm_status` is `critical`. This requires making a GET request to the `/usage/energy-usage` endpoint with the appropriate query parameter.\n",
      "\n",
      "Action: requests_get\n",
      "Action Input: {\n",
      "  \"url\": \"https://api-foundry-lab-ex7ziqmhsxf8.azurewebsites.net/usage/energy-usage\",\n",
      "  \"params\": {\"alarm_status\": \"critical\"},\n",
      "  \"output_instructions\": \"Extract the ids and names of data centers with critical alarm status.\"\n",
      "}\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"data_center_ids\": [\"DC-NYC1\", \"DC-CHI2\", \"DC-OMA1\"]\n",
      "}\n",
      "```\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe response contains the IDs of data centers with a critical alarm status. However, it does not include their names, which were part of the output instructions. It seems the API does not provide names for data centers in this endpoint. I will revise the final output to include only the IDs, as names are not available.\n",
      "\n",
      "Final Answer: The data centers with critical alarm status are:\n",
      "- ID: DC-NYC1\n",
      "- ID: DC-CHI2\n",
      "- ID: DC-OMA1\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3mThe data centers with critical alarm status are:\n",
      "- ID: DC-NYC1\n",
      "- ID: DC-CHI2\n",
      "- ID: DC-OMA1\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have retrieved the information about data centers with a 'critical' alarm status.  \n",
      "Final Answer: The data centers with critical alarm status are:  \n",
      "- ID: DC-NYC1  \n",
      "- ID: DC-CHI2  \n",
      "- ID: DC-OMA1  \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Update from node datacenter:\n",
      "\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What data centers are in 'critical'?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: datacenter_energy_usage\n",
      "\n",
      "The data centers with critical alarm status are:  \n",
      "- ID: DC-NYC1  \n",
      "- ID: DC-CHI2  \n",
      "- ID: DC-OMA1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": \"What data centers are in 'critical'?\"}]}):\n",
    "   pretty_print_messages(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6fa4e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update from node supervisor:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Update from node datacenter:\n",
      "\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What are the Data Center Space Types?\n",
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "You are a helpful assistant. Use only the information in the context below to answer the user's question. If the context does not contain the answer, respond with \"I don't know.\"\n",
      "\n",
      "Context:\n",
      "[lbnl-2024-united-states-data-center-energy-usage-report.pdf - Page 36]: 2024 United States Data Center Energy Usage Report 36 \n",
      "Table 4.1.  Data Center Space Types Considered in This Study \n",
      "Space Type \n",
      "Description \n",
      "Telco Edge \n",
      "Deployment of small closets/rooms to micro data centers \n",
      "and network infrastructure by communications companies \n",
      "as points of presence throughout their network \n",
      "Commercial Edge \n",
      "Network closets, server rooms, and micro-data centers \n",
      "deployed to support modern digital, infrastructure, and \n",
      "software delivery services to edge locations for \n",
      "commercial (focused on customer and business \n",
      "operations) and industrial (focused on supply chain and \n",
      "channel operations)  \n",
      "Small and Medium Businesses (SMB) \n",
      "SMB deployments in their own internal facilities \n",
      "Enterprise Branch \n",
      "Classic remote and branch office (ROBO) deployments \n",
      "for large enterprises in their own internal facilities \n",
      "(network closets, server rooms) \n",
      "Internal \n",
      "Data centers run by enterprises, internally, for their own \n",
      "use \n",
      "Communications Service Providers \n",
      "(Comms SPs) \n",
      "Data centers run by telecommunications/cable \n",
      "companies to support internal services required to enable \n",
      "provision of communications technology services to their \n",
      "customers \n",
      "Colocation ‚Äì Sm/Med Scale \n",
      "Data centers built by local colocation companies typically \n",
      "providing retail leasing at smaller scale \n",
      "Colocation ‚Äì Large Scale \n",
      "Data centers built by major colocation companies \n",
      "providing wholesale and retail colocation leasing, typically \n",
      "deploying large and mega datacenters  \n",
      "Hyperscale \n",
      "Data centers built by companies that deploy internet \n",
      "services and platforms at massive scale  \n",
      " \n",
      "Data centers are not uniformly spread across the United States. These data centers house \n",
      "computing equipment that operates continuously to support on-demand network requests, \n",
      "ranging from small setups in closets to massive warehouses with thousands of servers. Internal \n",
      "data centers are typically integrated into larger buildings and managed by businesses with their\n",
      "\n",
      "[lbnl-2024-united-states-data-center-energy-usage-report.pdf - Page 35]: 2024 United States Data Center Energy Usage Report 35 \n",
      " \n",
      " \n",
      "Figure 3.14.  Installed base for data center ethernet switch ports by port speed. \n",
      " \n",
      "Figure 3.14 shows the installed base of ethernet ports broken out by speed in the end of each \n",
      "year. Higher speed ports (> 50GB) begin to dominate the installed base around 2023, \n",
      "accounting for 64% of the total. Higher speeds continue to grow through 2028, with 200/400Gb \n",
      "reaching 34% and 100GB reaching 40% of the total. InfiniBand switch units grow rapidly, \n",
      "beginning in 2020 with under 2000 units and reaching 1.8 million units in 2028.  \n",
      " \n",
      "4. Data Center Infrastructure \n",
      "Data Center Classifications \n",
      "Although this study utilizes an IT equipment-based bottom-up model, it is still important to \n",
      "understand the types of data center facilities that IT equipment is being installed in, as different \n",
      "space types can have different operational characteristics as well as different cooling systems, \n",
      "which impact total electricity demand. In the 2016 report, our space types were defined by size \n",
      "and ownership/business (internal vs. service provider) categories. In this study, the space types \n",
      "are defined to align with new data available from IDC regarding the number, square footage, \n",
      "rack count, and other metrics of built data centers over time (IDC 2023b). These space types \n",
      "are described in Table 4.1. While these space types are not explicitly defined by size, for the \n",
      "most part they can be considered as either small, with an average square footage less than 150 \n",
      "(Telco Edge, Commercial Edge, SMB, and Enterprise Branch), midsize, with an average square \n",
      "footage of 2700 (Internal) and 6900 (Comms SPs), or large-scale, with average square footages \n",
      "of 11,000 for the colocation space types and 30,000 for hyperscale facilities (average square \n",
      "footage per module, not per entire facility/campus).\n",
      "\n",
      "[lbnl-2024-united-states-data-center-energy-usage-report.pdf - Page 38]: 2024 United States Data Center Energy Usage Report 38 \n",
      "We use the distribution in Figure 4.1 to assign IT equipment in our model into each space type. \n",
      "First, we calculate the total number of servers in each space type by multiplying the total \n",
      "installed base by the distribution. All AI accelerated servers are allocated evenly to the \n",
      "Hyperscale and Colocation-Large Scale categories. These servers are then broken out \n",
      "separately into an ‚ÄúAI‚Äù category to capture the unique cooling system configurations used for AI \n",
      "servers (a mix of liquid and air cooling). The total load calculated for AI servers is then \n",
      "distributed evenly between Hyperscale and Colocation-Large Scale. AI nonaccelerated servers \n",
      "go 80% into Hyperscale and 20% into Colocation-Large Scale. Then, multiple processor count \n",
      "servers go into Hyperscale, Colocation, and Internal space types proportional to how many \n",
      "servers are left in each category. Finally, single and dual processor servers are assigned to \n",
      "space types proportionate to how many spaces remain. \n",
      "Distribution of Cooling Systems Across Data Center Space Types \n",
      "The distribution of cooling systems across the United States is determined by combining \n",
      "market data with insights from industry experts. Specifically, we acquired market data from the \n",
      "Dell‚ÄôOro Group, which details annual manufacturing revenue segmented by primary heat \n",
      "rejection methods (such as chilled water, direct evaporative, indirect evaporative, and direct \n",
      "expansion) in North America. These market insights were then integrated with system costs (in \n",
      "dollars per megawatt) to estimate the distribution of major cooling system categories for each \n",
      "year. \n",
      " \n",
      "The market data offers an overview of the distribution of major cooling system categories, while \n",
      "insights from experts allow for a more detailed breakdown into specific systems, as outlined in \n",
      "this report. To achieve this, we collected data and insights from industry experts and formulated\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: document_search\n",
      "\n",
      "The data center space types considered in the study are:\n",
      "\n",
      "1. **Telco Edge**: Small closets/rooms to micro data centers and network infrastructure deployed by communications companies as points of presence throughout their network.\n",
      "\n",
      "2. **Commercial Edge**: Network closets, server rooms, and micro-data centers supporting digital infrastructure and software delivery services for commercial and industrial operations.\n",
      "\n",
      "3. **Small and Medium Businesses (SMB)**: Data center deployments in SMBs' own internal facilities.\n",
      "\n",
      "4. **Enterprise Branch**: Remote and branch office (ROBO) deployments for large enterprises in their own internal facilities (e.g., network closets, server rooms).\n",
      "\n",
      "5. **Internal**: Data centers run internally by enterprises for their own use.\n",
      "\n",
      "6. **Communications Service Providers (Comms SPs)**: Data centers operated by telecommunications/cable companies to support internal services for providing communications technology services.\n",
      "\n",
      "7. **Colocation ‚Äì Small/Medium Scale**: Data centers built by local colocation companies, typically providing retail leasing at a smaller scale.\n",
      "\n",
      "8. **Colocation ‚Äì Large Scale**: Data centers built by major colocation companies, offering wholesale and retail colocation leasing, often deploying large and mega data centers.\n",
      "\n",
      "9. **Hyperscale**: Data centers built by companies deploying internet services and platforms at massive scale. \n",
      "\n",
      "These space types vary in size, operational characteristics, and cooling systems.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": \"What are the Data Center Space Types?\"}]}):\n",
    "   pretty_print_messages(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e89ed35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update from node supervisor:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Update from node weather:\n",
      "\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: weather\n",
      "\n",
      "The weather in San Francisco is currently 60 degrees and foggy.\n",
      "\n",
      "\n",
      "Update from node supervisor:\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]}):\n",
    "   pretty_print_messages(step)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
